{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e01c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from utils.vector import retrive\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cad353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:amxIxHpfqzuUzoRhwyXGniCymrUOVFAi@switchyard.proxy.rlwy.net:29714/railway\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collection_name = \"uploaded_documents\"\n",
    "\n",
    "non_prompt = \"\"\"You are a **RAG Chat Retriever Agent**.\n",
    "Your responsibilities:\n",
    "1. Understand the user question deeply.\n",
    "2. ALWAYS use the `data_retriever` tool.\n",
    "3. Generate 3-5 short keyword queries (2-4 words) using different angles (if need using common terminologies about user questions). \n",
    "4. Call the tool repeatedly until:\n",
    "   - You find relevant documents, OR\n",
    "   - All 3-5 queries fail ‚Üí then use AI knowledge.\n",
    "\n",
    "\n",
    "### üîç RETRIEVAL RULES\n",
    "- Query format: 2-4 meaningful words only.\n",
    "- You MUST try up to 4 different queries:\n",
    "  1) Main keyword  \n",
    "  2) Synonym / related term  \n",
    "  3) Domain / category keyword  \n",
    "\n",
    "- After EACH retrieval:\n",
    "  - If the documents are relevant ‚Üí STOP searching and ANSWER.\n",
    "  - If irrelevant ‚Üí try the next query.\n",
    "\n",
    "\n",
    "### üß† ANSWER GENERATION RULES\n",
    "When documents are found:\n",
    "- DO NOT repeat the document text.\n",
    "- DO NOT summarize the document blindly.\n",
    "- **GENERATE A FULL NATURAL-LANGUAGE ANSWER** using your own explanation ability.\n",
    "- Use the document only as reference.\n",
    "- Combine reasoning + document facts.\n",
    "- Cite each point like this:\n",
    "   <your explanation> [üîó](<document url>)\n",
    "\n",
    "- At end, write:\n",
    "  **Source: Document Knowledge**\n",
    "\n",
    "When NO documents are found after 5th attempts:\n",
    "- Use your own knowledge to answer.\n",
    "- End with:\n",
    "  **Source: Web Search**\n",
    "\n",
    "\n",
    "### üìò WHAT YOUR ANSWER MUST LOOK LIKE\n",
    "A correct answer has:\n",
    "\n",
    "1. A clear explanation in your own words  \n",
    "2. Clearl bullet points that answer the user  \n",
    "3. Each bullet with a source tag  \n",
    "4. Example:\n",
    "\n",
    "[\n",
    "  The system requires user authentication before accessing private data. [üîó](<document url>)\n",
    "\n",
    "  Logging should be enabled to track suspicious activity. [Web Search (AI Response)]\n",
    "]\n",
    "\n",
    "\n",
    "### üìå STRICT RULES\n",
    "- NEVER output only document titles or raw document lines.\n",
    "- NEVER output only metadata.\n",
    "- ALWAYS produce a full explanation.\n",
    "- ALWAYS use at least ONE tool call per message.\n",
    "- NEVER hallucinate page numbers or doc names.\n",
    "- If no document found after all attempts ‚Üí default to AI.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def data_retriever(user_request: str):\n",
    "    \"\"\"\n",
    "    Retrieves existing content from vector DB based on user request.\n",
    "\n",
    "    Args:\n",
    "        user_request: The search query.\n",
    "\n",
    "    Returns:\n",
    "        str: Retrieved content or error message.\n",
    "    \"\"\"\n",
    "    print(\"data_retriever\\n\"*5)\n",
    "    print(\"user_request:\\n\", user_request)\n",
    "    print()\n",
    "    try:\n",
    "        existing_content = retrive(user_request, collection_name=collection_name)\n",
    "        return existing_content\n",
    "    \n",
    "    except:\n",
    "        return \"‚ùå Error retrieving content\"\n",
    "\n",
    "# \"postgresql://postgres:amxIxHpfqzuUzoRhwyXGniCymrUOVFAi@switchyard.proxy.rlwy.net:29714/railway\"   # normal DB\n",
    "DB_URI = os.getenv(\"DATABASE_URL\")\n",
    "print(DB_URI)\n",
    "\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "rag_agent = create_agent(\n",
    "    name=\"RAG_agent\",\n",
    "    model=\"google_genai:gemini-2.5-flash\",\n",
    "    tools=[data_retriever],\n",
    "    system_prompt=non_prompt,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bf62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config,\n",
    "    *,\n",
    "    store: BaseStore,    \n",
    "):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    last_user_msg = state[\"messages\"][-1].content\n",
    "\n",
    "    # ---------------- Load memories -----------------------\n",
    "    memories = store.search(namespace, query=last_user_msg)\n",
    "    memory_text = \"\\n\".join([m.value[\"data\"] for m in memories])\n",
    "    sys_msg = f\"USER_MEMORIES:\\n{memory_text}\"\n",
    "\n",
    "    # ---------------- Store new memory ---------------------\n",
    "    if \"remember\" in last_user_msg.lower():\n",
    "        memory_value = last_user_msg.replace(\"remember\", \"\").strip()\n",
    "        if memory_value:\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory_value})\n",
    "\n",
    "    # ---------------- Call agent ----------------------------\n",
    "    final_messages = [{\"role\": \"system\", \"content\": sys_msg}] + state[\"messages\"]\n",
    "    response = rag_agent.invoke({\"messages\": final_messages}, config)\n",
    "\n",
    "    return {\"messages\": response[\"messages\"]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2737554",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,  \n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    store.setup()\n",
    "    checkpointer.setup()\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "\n",
    "# Attach Postgres memory & checkpointer\n",
    "store = PostgresStore.from_conn_string(DB_URI)\n",
    "checkpointer = PostgresSaver.from_conn_string(DB_URI)\n",
    "\n",
    "# store.setup()\n",
    "# checkpointer.setup()\n",
    "\n",
    "graph = builder.compile(\n",
    "    store=store,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78431b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_GeneratorContextManager' object has no attribute 'get_next_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m config = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m,  \n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m,  \n\u001b[32m      5\u001b[39m     }\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHay! do you remember me?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Madhavan\\Code\\RAG_sample\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2579\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2576\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2577\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2579\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2580\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[32m   2600\u001b[39m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[32m   2601\u001b[39m     runner = PregelRunner(\n\u001b[32m   2602\u001b[39m         submit=config[CONF].get(\n\u001b[32m   2603\u001b[39m             CONFIG_KEY_RUNNER_SUBMIT, weakref.WeakMethod(loop.submit)\n\u001b[32m   (...)\u001b[39m\u001b[32m   2606\u001b[39m         node_finished=config[CONF].get(CONFIG_KEY_NODE_FINISHED),\n\u001b[32m   2607\u001b[39m     )\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Madhavan\\Code\\RAG_sample\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1012\u001b[39m, in \u001b[36mSyncPregelLoop.__init__\u001b[39m\u001b[34m(self, input, stream, config, store, cache, checkpointer, nodes, specs, trigger_to_nodes, durability, manager, interrupt_after, interrupt_before, input_keys, output_keys, stream_keys, migrate_checkpoint, retry_policy, cache_policy)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28mself\u001b[39m.stack = ExitStack()\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer:\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_get_next_version = \u001b[43mcheckpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next_version\u001b[49m\n\u001b[32m   1013\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_put_writes = checkpointer.put_writes\n\u001b[32m   1014\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_put_writes_accepts_task_path = (\n\u001b[32m   1015\u001b[39m         signature(checkpointer.put_writes).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mtask_path\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1016\u001b[39m         \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1017\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: '_GeneratorContextManager' object has no attribute 'get_next_version'"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"2\",  \n",
    "        \"user_id\": \"1\",  \n",
    "    }\n",
    "}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Hay! do you remember me?\"\n",
    "    }]}, config, stream_mode=\"values\",\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0132a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c899ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b5d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b0508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bebe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6975b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def RAG_agent(user_message: str, thread_id: str, user_id=\"1\"):\n",
    "    \"\"\"\n",
    "    Main function used by FastAPI.\n",
    "    Uses long-term Postgres conversation history + user memory.\n",
    "    \"\"\"\n",
    "\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,   # chat history thread\n",
    "            \"user_id\": user_id,       # long-term memory owner\n",
    "        }\n",
    "    }\n",
    "\n",
    "    result_text = \"\"\n",
    "\n",
    "    # stream mode returns incremental messages\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user_message)]},\n",
    "        config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        msg = chunk[\"messages\"][-1]\n",
    "        result_text = msg.content\n",
    "\n",
    "    return result_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_agent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
