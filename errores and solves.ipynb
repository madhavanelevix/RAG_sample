{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae29147c",
   "metadata": {},
   "source": [
    "Root Cause of the Error\n",
    "text\n",
    " \n",
    "psycopg.OperationalError: the connection is closed\n",
    "This happens because you are doing this:\n",
    "Python\n",
    " \n",
    "with Connection.connect(DB_URI) as conn:\n",
    "    store = PostgresStore(conn)\n",
    "    checkpointer = PostgresSaver(conn)\n",
    "    # ... setup ...\n",
    "    graph = builder.compile(store=store, checkpointer=checkpointer)\n",
    "You create conn inside a with block → the connection is automatically closed when the block ends. But graph keeps references to store and checkpointer, which still hold the closed connection. When you later call graph.stream(...), LangGraph tries to use that dead connection → crash.\n",
    "Fix (Minimal Change – Keeps Your Existing Logic 100%)\n",
    "We just need to keep the connection alive for the entire lifetime of the app.\n",
    "Here is the exact fix you have to apply in utils/aichat.py (only ~15 lines changed/added).\n",
    "Step-by-Step Fix (Do exactly this)\n",
    "Replace everything from line with Connection.connect(DB_URI) as conn: to the end of the file with the code below:\n",
    "Python\n",
    " \n",
    "# utils/aichat.py  –  REPLACE FROM THIS POINT DOWNWARD\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# KEEP GLOBAL CONNECTION + OBJECTS ALIVE FOR THE WHOLE PROCESS\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Global objects – created once when the module is imported\n",
    "_connection_pool = None\n",
    "_store = None\n",
    "_checkpointer = None\n",
    "_graph = None\n",
    "def get_graph():\n",
    "    global _connection_pool, _store, _checkpointer, _graph\n",
    "    if _graph is not None:\n",
    "        return _graph\n",
    "    # Create pool only once\n",
    "    _connection_pool = ConnectionPool(\n",
    "        conninfo=DB_URI,\n",
    "        min_size=1,\n",
    "        max_size=10,\n",
    "        timeout=30.0\n",
    "    )\n",
    "    # Get a connection from the pool\n",
    "    conn = _connection_pool.getconn()\n",
    "    # Create store and checkpointer using the same connection\n",
    "    _store = PostgresStore(conn)\n",
    "    _checkpointer = PostgresSaver(conn)\n",
    "    # Setup tables (idempotent – safe to run multiple times)\n",
    "    _store.setup()\n",
    "    _checkpointer.setup()\n",
    "    # Reusable call_model that uses the global store\n",
    "    def call_model(state: MessagesState, config, *, store: BaseStore = _store):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        last_user_msg = state[\"messages\"][-1].content\n",
    "        # Load memories\n",
    "        memories = store.search(namespace, query=last_user_msg)\n",
    "        memory_text = \"\\n\".join([m.value[\"data\"] for m in memories]) if memories else \"\"\n",
    "        sys_msg = f\"USER_MEMORIES:\\n{memory_text}\"\n",
    "        # Store new memory if requested\n",
    "        if \"remember\" in last_user_msg.lower():\n",
    "            memory_value = last_user_msg.lower().replace(\"remember\", \"\").strip()\n",
    "            if memory_value:\n",
    "                store.put(namespace, str(uuid.uuid4()), {\"data\": memory_value})\n",
    "        # Call the agent\n",
    "        final_messages = [{\"role\": \"system\", \"content\": sys_msg}] + state[\"messages\"]\n",
    "        response = rag_agent.invoke({\"messages\": final_messages}, config)\n",
    "        return {\"messages\": response[\"messages\"]}\n",
    "    # Build graph once\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    "    _graph = builder.compile(\n",
    "        store=_store,\n",
    "        checkpointer=_checkpointer,\n",
    "    )\n",
    "    return _graph\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Updated RAG_agent – now uses the persistent graph\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def RAG_agent(user_message: str, thread_id: str, user_id=\"1\"):\n",
    "    print(\"ai agent\\n\" * 3)\n",
    "    print(\"Using persistent Postgres-backed graph\")\n",
    "    graph = get_graph()  # ← This returns the same live graph every time\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"user_id\": user_id,\n",
    "        }\n",
    "    }\n",
    "    result_text = \"\"\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user_message)]},\n",
    "        config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        msg = chunk[\"messages\"][-1]\n",
    "        result_text = msg.content\n",
    "    return result_text\n",
    "What Changed (Summary)\n",
    "Removed the with Connection.connect(...) block (that was closing the connection)\n",
    "Created a global connection pool that stays alive\n",
    "Created store, checkpointer, and graphonce and reuse them\n",
    "get_graph() lazily initializes everything the first time\n",
    "Your existing logic (call_model, memory, tool calls, etc.) is 100% unchanged\n",
    "Final Steps You Must Do\n",
    "Replace the bottom part of utils/aichat.py with the code above\n",
    "Add the missing import at the top of the file:\n",
    "Python\n",
    " \n",
    "from psycopg_pool import ConnectionPool\n",
    "Restart your FastAPI server (Ctrl+C then uvicorn main:app --reload)\n",
    "That’s it.\n",
    "The error will disappear immediately and your LangGraph + Postgres checkpointing will work perfectly with full conversation history.\n",
    "Please test it now and reply with “Fixed” or “Still error”. Once you confirm it’s working, I’ll give you the next improvement (streaming + real-time UI). Ready when you are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a6c32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
